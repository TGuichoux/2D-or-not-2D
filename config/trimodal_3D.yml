#name: 3D_multimodal_context-2

train_data_path: /data/guichoux/TED/ted_dataset/lmdb_train
val_data_path: /data/guichoux/TED/ted_dataset/lmdb_val
test_data_path: /data/guichoux/TED/ted_dataset/lmdb_test

wordembed_dim: 300
wordembed_path: /data/guichoux/TED/fasttext/crawl-300d-2M-subword.bin  # from https://fasttext.cc/docs/en/english-vectors.html
#freeze_wordembed: true

model_save_path: output/train_multimodal_context/3D_multimodal-checkpoint
random_seed: -1

# model params
model: multimodal_context
mean_dir_vec_3d: [ 0.0154009, -0.9690125, -0.0884354, -0.0022264, -0.8655276, 0.4342174, -0.0035145, -0.8755367, -0.4121039, -0.9236511, 0.3061306, -0.0012415, -0.5155854,  0.8129665,  0.0871897, 0.2348464,  0.1846561,  0.8091402,  0.9271948,  0.2960011, -0.013189 ,  0.5233978,  0.8092403,  0.0725451, -0.2037076, 0.1924306,  0.8196916]
mean_pose_3d: [ 0.0000306,  0.0004946,  0.0008437,  0.0033759, -0.2051629, -0.0143453,  0.0031566, -0.3054764,  0.0411491,  0.0029072, -0.4254303, -0.001311 , -0.1458413, -0.1505532, -0.0138192, -0.2835603,  0.0670333,  0.0107002, -0.2280813,  0.112117 , 0.2087789,  0.1523502, -0.1521499, -0.0161503,  0.291909 , 0.0644232,  0.0040145,  0.2452035,  0.1115339,  0.2051307]
mean_dir_vec_2d: [ 0.0154009, -0.9690125, -0.0022264, -0.8655276, -0.0035145, -0.8755367, -0.9236511, 0.3061306, -0.5155854,  0.8129665, 0.2348464,  0.1846561,  0.9271948,  0.2960011,  0.5233978,  0.8092403, -0.2037076, 0.1924306]
mean_pose_2d: [ 0.0000306,  0.0004946,  0.0033759, -0.2051629,  0.0031566, -0.3054764,  0.0029072, -0.4254303, -0.1458413, -0.1505532, -0.2835603,  0.0670333, -0.2280813,  0.112117,  0.1523502, -0.1521499,  0.291909 , 0.0644232,  0.2452035,  0.1115339]


n_layers: 4
hidden_size: 300
z_type: speaker  # speaker, random, none
#input_context: #both  # both, audio, text, none
pose_dim: 27
dimension: 3

# train params
epochs: 100
batch_size: 128
learning_rate: 0.0005
loss_regression_weight: 500
loss_gan_weight: 5.0
loss_warmup: 10
loss_kld_weight: 0.1
loss_reg_weight: 0.05

# eval params
eval_net_path: 'output/train_h36m_gesture_autoencoder/gesture_autoencoder_checkpoint_best.bin' #'output/train_h36m_gesture_autoencoder/3D_retrain_h36m_gesture_autoencoder/3D-autoencoder_checkpoint_best.bin'

# dataset params
motion_resampling_framerate: 15
n_poses: 34
n_pre_poses: 4
subdivision_stride: 10
loader_workers: 4